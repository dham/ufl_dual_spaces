\documentclass[a4paper,11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{mathpazo}
\usepackage[margin=2.5cm]{geometry}
\usepackage{hyperref}
\usepackage[finalizecache=true,cachedir=.]{minted}
%\usepackage[frozencache=true,cachedir=.]{minted}
\usepackage{amsmath}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}{Definition}[section]
\newtheorem{note}{Note}[section]

\usepackage[style=authoryear]{biblatex}
\addbibresource{bibliography.bib}

\title{Closing and opening the Unified Form Language}
\author{David A. Ham, India Marsden, Reuben W. Nixon-Hill, and Nacime Bouziani}
%\date{January 2021}

\begin{document}

\maketitle

\begin{abstract}
    FIXME
\end{abstract}

\section{Introduction}

The Unified Form Language (UFL) is a domain-specific language, embedded in Python, for the description of variational forms \parencite{alnaes2014}. UFL plays a key role in the creation of high-level software frameworks for the finite element method, since it enables the users of those frameworks to write down the variational form of essentially any PDE. The software framework then generates, compiles and executes high performance low level code for the assembly of the form, and solves the resulting linear or nonlinear system. UFL has been widely adopted, among others by the Firedrake \parencite{rathgeber2017}, FEniCS \parencite{logg2012}, it's reincarnation FEniCSx \parencite{baratta_2023}, and DUNE \parencite{dedner2020}.

As its name suggests, UFL is a language used to describe multilinear forms. Typically these forms are to be used in a finite-dimensional variational problem, specifically a finite element problem. UFL has not, hitherto, concerned itself with the spaces to which forms belong or into which they map: this has been the concern of the assembler, such as Firedrake or FEniCSx and, to some extent, the linear algebra backend (for example PETSc). In particular, the result of assembling a UFL form is not a UFL object. This creates something of a closure problem in systems that use UFL: there are operations visible to the UFL user which result in objects that are not UFL objects, or which rely on bespoke functions where a more closed system would have a first class operator. Examples of this include:

\begin{enumerate}
    \item Interpolation, which is a form whose range space is the dual of the space being interpolated into.
    \item The automated adjoint framework dolfin-adjoint\parencite{farrell2013, mitusch2019}, which currently has hitherto relied on intricate reasoning to work out which objects are primal or dual, where this should be obvious from their type.
\end{enumerate}

Conversely, finite element problems rarely exist in isolation: a complete system to be simulated may include operators  not expressible in the vector calculus notation of variational forms. A topical example is the inclusion of neural network operators to represent terms in equations for which data exists but theory is lacking. 

In this paper, we present and justify extensions to UFL which extend the language to support the dual spaces to the finite element function spaces that the language already supports. Building on this, we will present a symbolic interpolation operator, and a foreign function interface which enables non-finite element operators to be included in UFL expressions. The extensions presented here have been incorporated in the main development version of UFL used by both FEniCSx and Firedrake, though at this stage only Firedrake exploits this functionality, some of which has been employed in \textcite{bouziani_2021}, \textcite{bouziani_2023}, \textcite{nixon-hill_2024}. This paper will focus on the extensions to UFL, introducing Firedrake code only to the extent necessary to illustrate the UFL.

\section{Preliminaries}

In this section we restate without proof some essential definitions and results, in order to establish notation and as a reference point for readers less versed in the relevant analysis. We will assume that there is a domain $\Omega \subset \mathbb{R}^n$ for some $n>0$ which is the region on which we will calculate. $\Omega$ may be of dimension $n$, or it may be of a lower dimension, allowing for the representation of immersed manifold domains \parencite{rognes_2013}. It may even be a collection of isolated points, representing data defined on a point cloud \parencite{nixon-hill_2024}.

\begin{definition}[Function space]
    A \emph{function space} is a vector space over a field K comprising functions $\Omega\rightarrow K^m$.
\end{definition}
That is to say, if $V$ is a function space and $f\in V$ then $f$ associates a value in $K^m$ with each point in the domain $\Omega$. The field $K$ will be either $\mathbb{R}$ or $\mathbb{C}$.

\begin{definition}[parametrised multilinear form]\label{kform}
    A \emph{multilinear form} of \emph{arity} $k$  with $m$ \emph{parameters} is a mapping from $k(\ge0) + m(\ge0)$ vector spaces to $K$. That is, a function:
    \begin{gather} 
    a:W_{m-1} \times W_{m-2} \times \ldots \times W_{0} \times V_{k-1} \times V_{k-2} \times \ldots \times V_{0} \rightarrow K\\
    a(w_{m-1}, w_{m-2}, \ldots, w_0; v_{k-1}, v_{k-2}, \ldots, v_0) \in K
    \end{gather} 
    for suitable vector spaces $V_0\ldots V_{k-1}$, $W_0\ldots W_{m-1}$. The form must be linear in the arguments $v_i, i>=1$ but may be nonlinear in the parameters $w_i$. The form must be conjugate linear in the first argument $w_0$. Of course if $K=\mathbb{R}$ then this is simply linear.
\end{definition}

\begin{note}
    The argument numbering in definition \ref{kform} is deliberately from right to left. This reflects the numbering of arguments in UFL. It also caters for a difference in notation between forms and linear algebra: taking the action of a bilinear form on a vector conventionally replaces the left-most argument, but the equivalent matrix-vector product consumes the right-most dimension of the matrix (the columns).
\end{note}

Although UFL supports multilinear forms of any arity, the needs of the finite element method and the practical difficulty of assembling higher dimensional sparse tensors mean that in practice the arity of forms will be 0 (a functional) 1, (a linear/anti-linear form) or 2 (a bilinear/sesquilinear form). 

\begin{definition}[(Anti-)dual space]\label{dualspace}
    If $V$ is a vector space then $V^*$, the (anti-)dual space to $V$, is the space of bounded conjugate linear functionals $V\rightarrow K$.
\end{definition}

In order to minimise notational clutter, throughout the rest of this paper we will simply refer to the terminology for the real case, except where it is relevant to highlight the complex case. Further, we will not include parameters to forms except when those parameters explicitly feature in the argument.

\begin{theorem}[Dual basis]
If $\{\phi_i\}$ is a basis for a finite vector space $V$ then there exists $\{\phi_i^*\}$ a basis for $V^*$ such that:
\begin{equation} 
    \phi_i^*(\phi_j) = \delta_{ij}
\end{equation} 
The basis $\{\phi_i^*\}$ is termed the \emph{dual basis}.
\end{theorem}
Where it is necessary to make the distinction, we will refer to the space to which a dual space is dual as the \emph{primal space} and its basis as the \emph{primal basis}. 
\begin{definition}{Reflexive vector space}
    A reflexive vector space is one for which $(V^{*})^{*}$ is isomorphic to $V$ under the canonical map. That is, we can identify $(V^*)^*$ and $V$.
\end{definition}
\begin{theorem}
    All finite-dimensional vector spaces are reflexive.
\end{theorem}
This is a completely intuitive result. If $u\in V$ and $v\in V^*$ then this induces a $u'$ in $(V^*)^*$ given by:
\begin{equation}
    u'(v) = v(u)    
\end{equation}
We simply identify $u'$ and $u$. Since the dimensions of the spaces match and the functionals are linear, this identification is an isometric isomorphism. In other words we can't distinguish the spaces so the identification is valid. We also state without proof the following well-known result:

\begin{theorem}
    All Hilbert spaces are reflexive.
\end{theorem}

Since UFL function spaces are finite-dimensional Hilbert spaces which result from the discretisation of infinite-dimensional Hilbert spaces, all of the function spaces with which we are concerned are reflexive.

\subsection{Dual spaces and multilinear forms}

In definition \ref{kform} and elsewhere, we use a notation for multilinear forms which takes a Cartesian product of spaces and returns a scalar. For example, we write the signature of a bilinear form as:
\begin{equation}
    V_1 \times V_0 \rightarrow K
\end{equation} 
This notation emphasises that the form is a function which takes two vectors and returns a scalar. However we could just as well Curry this form and write:
\begin{equation}  
    V_1 \rightarrow V_0 \rightarrow K
\end{equation} 
This notation is left-associative, so this means:
\begin{equation} 
    V_1 \rightarrow (V_0 \rightarrow K)
\end{equation} 

From definition \ref{dualspace}, the space of linear 1-forms on vector space $V$ is the same thing as $V^*$. 
A direct consequence of this is the following equivalence:
\begin{equation} 
    V_1 \times V_0 \rightarrow K = V_1 \rightarrow V_0^*
\end{equation}
This says that every form can equivalently be thought of as an operator mapping into the dual space of its first argument.

\section{UFL Forms}

UFL is the Unified Form Language \parencite{alnaes2014}. As one might expect, it provides support for multilinear forms. UFL is a symbolic algebra language embedded in the Python programming language. In common with other symbolic languages, it provides for symbols to stand for unknown values, including the arguments to multilinear forms. UFL is a purely symbolic language which problem solving environments such as Firedrake and FEniCS extend by subclassing in order to attach numerical data and actually solve problems. In understanding how UFL objects do (or should) behave, it is sometimes necessary to consider how they would be integrated into the problem solving environment, and especially what should happen when a form is assembled.

In an attempt to avoid replicating \textcite{alnaes2014} and the documentation of UFL\footnote{\url{https://docs.fenicsproject.org/ufl/main/}}, we will start here from UFL's function space and gloss over the cells, meshes, and finite elements from which these are constructed. A \mintinline{python}|ufl.FunctionSpace| is a symbolic object representing a (primal) finite element space. The scalar field over which UFL operates is selected by the problem solving environment. In this section we will assume real-valued forms in order to minimise notational clutter.

If \mintinline{python}|V| is a \mintinline{python}|ufl.FunctionSpace| then \mintinline{python}|c = ufl.Coefficient(V)| defines a \emph{known} function in \mintinline{python}|V|. Conversely, \mintinline{python}|a = ufl.Argument(V, 0)|\footnote{Users more frequently write \mintinline{python}|a = ufl.TestFunction(V)|, but that is simply syntactic sugar. A test function is just argument 0 to a form.} defines a placeholder symbol for an \emph{unknown} function in \mintinline{python}|V|.
Consequently, 
\mint{python}|f_0 = c * dx| 
is a symbolic expression for the integral of \mintinline{python}|c| over the domain and represents a scalar value. \mintinline{python}|f_0| is a Python object of type \mintinline{python}|ufl.Form|. Since it contains no arguments, it is a 0-linear form, or functional. In contrast, 
\mint{python}|f_1 = conj(a) * dx|
represents the integration of the unknown function \mintinline{python}|a| over the domain. It's therefore a linear form, or a function in $V\rightarrow K$.

In order to make the argument order clear, we introduce a second function space, \mintinline{python}|W|. We  define \mintinline{python}|b = ufl.Argument(W, 1)|\footnote{Equivalently, \mintinline{python}|b = ufl.TrialFunction(W)|.} and create the simplest bilinear form:
\mint{python}|f_2 = inner(c, b) * dx|
This is a function in $W\times V\rightarrow K$. The inner product is Hermitian, so we could equivalently have written:
\mint{python}|f_2 = conj(inner(b, c)) * dx|
The argument order is determined by the declared argument numbers, not by where the arguments appear in the expression defining the form.

\subsection{Expressions}

The integrands of the forms given above are instances of \mintinline{python}|UFL.expression|. UFL expressions are functions $\Omega\rightarrow K^n$ for some $n>0$. They are composed of terminal expressions combined by mathematical operators. In addition to coefficients and arguments, the terminals can be the spatial coordinate ($x\in\Omega$) or mesh-related geometric quantites such as facet normals and cell volumes. For details see \textcite{alnaes2014} section 3.2. For the purposes of this paper the relevant factor is that UFL expressions are primal quantities drawn from a function space more general than finite element spaces. Symbolically, UFL treats expressions as capable of evaluation at any point in the domain and Gateaux differentiable with respect to any coefficient. The treatment of undefined evaluations of expressions, for example at discontinuities, is left to the problem solving environment.

\subsection{Assembly}

The problem solving environment takes symbolic UFL forms and evaluates them. In Firedrake and FEniCS, the operation which does this is called assembly. The problem solving environment encodes in its subclass of
\mintinline{python}|ufl.FunctionSpace| a basis for the function space. We will write ${\phi_i}$ for the basis for $V$ and ${\psi_i}$ for the basis for $W$. The problem solving environment will also implement its own subclass of \mintinline{python}|ufl.Coefficient|, in Firedrake and FEniCS this is called a \mintinline{python}|Function|. If \mintinline{python}|c| is a \mintinline{python}|Coefficient|, then mathematically:
\begin{equation}
    c = c_i\phi_i
\end{equation}
The consequence of this is that the core of the implementation of a \mintinline{python}|Function| is a reference to a \mintinline{python}|FunctionSpace| (which encodes the basis $\{\phi_i\}$) and a vector of values $c_i$. The latter give the \mintinline{python}|Function| its numerical value, while the former gives that value a mathematical meaning.

If we execute the Firedrake code:
\begin{minted}{python}
    g = assemble(f_0)
\end{minted}
Then the integral is evaluated and $g$ is a scalar value. Mathematically, nothing has really happened: $g$ and $f_0$ represent the same scalar value. Computationally, however, we have gone from a symbolic object which evaluates to a scalar, to the scalar itself.

Consider the following case:
\begin{minted}{python}
    h = assemble(conj(a)*dx)
\end{minted}
The integrand contains the argument, or unknown \mintinline{python}|Function|, \mintinline{python}|a|. In other words, the assembler needs to evaluate
\begin{equation}
    \begin{split}
        h(a) &= \int \bar{a}\,\mathrm{d}x\\
        &= \int \bar{a}_i \phi_i\,\mathrm{d}x
    \end{split}
\end{equation}
for unknown values $a_i$. Here we note that UFL assumes that the basis of a complex-valued space still has real basis functions. The $a_i$ are scalar so they can be lifted out of the integral:
\begin{equation}
    \int \bar{a}\,\mathrm{d}x = \int \phi_i\,\mathrm{d}x\ \bar{a}_i
\end{equation}
Observe the integrals no longer contain unknown values and can hence be evaluated. 
Next, we use the fact that $\phi^*_i(\phi_j) = \delta_{ij}$. Hence:
\begin{equation}
    \begin{split}
        h(a) &= \int \phi_i\,\mathrm{d}x\ \phi^*_i(\phi_j) \bar{a}_j\\
        &= \int \phi_i\,\mathrm{d}x\ \phi^*_i(a_j\phi_j)\quad\textrm{by antilinearity}\\
        &= \int \phi_i\,\mathrm{d}x\ \phi^*_i(a)\\
    \end{split}
\end{equation}
Noting that $a$ is simply a placeholder argument, we have now expressed $h$ in terms of the basis for $V^*$: 
\begin{equation}
    h = h_i \phi^*_i\quad \textrm{where:} \quad h_i = \int \phi_i\ \mathrm{d}x \label{eq:cofunction}
\end{equation}
The consequence of this is that the value of $h$ is encoded in a vector of numbers, of the same size as that which encodes $c$. One might argue that the only purpose of assembly is to create a linear system to be solved, so the vector of values is the only thing which is required. This has been the FEniCS approach. This approach is problematic because it neglects the fact that assembled operators can and are used by users in other contexts. 

What is missing, of course, is a reference to the dual basis $\{\phi^*_i\}$. The challenge is that UFL hitherto did not have a class encoding $\{\phi^*_i\}$, and hence did not have a suitable class for $h$. The previous Firedrake approach was to appeal to the isomorphism between $V$ and $V^*$ and simply make \mintinline{python}|h| a \mintinline{python}|Function|. This has the advantage of preserving the link between the numerical values and the function space, but at the expense of incorrectly labelling $h$ as being in $V$. 

% What we should really do is associate the list of coefficients $h_i$ with an object encoding the dual basis, in a manner analogous to the association between a list of coefficients and the basis for a function space in a \mintinline{python}|Function|. 

% To illustrate the manner in which the assembled form encodes the same information as the symbolic form, observe that:
% \begin{equation}
%     h(c) = f_1(c) = \int c\,\mathrm{d}x = f_0 = g
% \end{equation}
% However the evaluation of $h(c)$ is actually accomplished like this:
% \begin{equation}
%     \begin{split}
%         h(c) &=  h_i \phi^*_i(c_j\phi_j)\\
%         &= h_i \phi^*_i(\phi_j) c_j\\
%         &= h_i \delta_{ij}c_j\\
%         &= h_i c_i
%     \end{split}
% \end{equation}
% So the assembly has turned the evaluation of an integral into the dot product between two vectors.

\section{UFL dual types}

Here we present a fully mathematically consistent answer to the question of what should result from assembly by extending UFL to support dual spaces, objects representing assembled operators, and the operations on them. Table \ref{tab:dual_types} shows the key new classes. 

\begin{table}[htbp]
    \centering
    \begin{tabular}{ll}
        Primal quantity & Dual quantity \\\hline
        \mintinline{python}|ufl.FunctionSpace| & \mintinline{python}|ufl.DualSpace| \\
        \mintinline{python}|ufl.Coefficient| & \mintinline{python}|ufl.Cofunction| \\
        \mintinline{python}|ufl.Argument| & \mintinline{python}|ufl.Coargument| \\
    \end{tabular}
    \caption{Dual types corresponding to primal finite element spaces, and to known and unknown functions in those spaces. The more consistent name \mintinline{python}|ufl.Cocoefficient| was rejected as confusing and risible.}
    \label{tab:dual_types}
\end{table}

\section{Dual spaces}

\mintinline{python}|ufl.DualSpace| is the most straightforward of the new classes, the difference between it and the corresponding \mintinline{python}|ufl.FunctionSpace| is essentially only the symbolic indication that the former is the latter's dual. Objects of either class have a \mintinline{python}|dual| method which returns the corresponding dual object. In the case of \mintinline{python}|ufl.DualSpace|, the reflexivity of finite element spaces justifies returning a \mintinline{python}|ufl.FunctionSpace| rather than creating a further double dual space type.

UFL also supports product spaces whose values have components in two or more function spaces:
\begin{equation}
    W = V_0 \times \ldots V_{k-1}     
\end{equation}
These are represented by objects of type \mintinline{python}|ufl.MixedFunctionSpace| whose components are of type \mintinline{python}|ufl.FunctionSpace|. Rather than introduce a dual mixed function space, \mintinline{python}|ufl.MixedFunctionSpace| is now allowed to have components of type \mintinline{python}|ufl.DualSpace|. This allows for the additional flexibility of mixed spaces with both primal and dual components. The practical use of such spaces is illustrated in FIXME. 

It is also useful for users to interrogate objects to determine if they are primal or dual. The \mintinline{python}|ufl.is_primal| and \mintinline{python}|ufl.is_dual| predicates are introduced for this purpose. Notably, these predicates do not obey a law of excluded middle since a \mintinline{python}|ufl.MixedFunctionSpace| with both primal and dual components is itself neither primal nor dual.

\subsection{Cofunctions and coarguments}

The original motivation for these extensions was to be able to represent a concrete member of a dual space, for example the cofunction $h$ in \eqref{eq:cofunction}. UFL now represents these values of objects of type \mintinline{python}|ufl.Cofunction|, defined with respect to a \mintinline{python}|ufl.DualSpace| in the same way that a \mintinline{python}|ufl.Coefficient| is defined with respect to a \mintinline{python}|ufl.FunctionSpace|. The problem solving environment's subclass of this (for example \mintinline{python}|firedrake.Cofunction|) will augment this with a vector of numerical coefficients just as is the case for its subclass of \mintinline{python}|ufl.Coefficient|. Similarly in order to be able to create operators that act on cofunctions, UFL also now has a \mintinline{python}|ufl.Coargument| class, representing an unknown cofunction.

\subsection{Cofunctions are forms, not expressions}

Cofunctions, and coarguments, differ from coefficients and arguments in that they do not represent functions from the domain to $K^m$, but rather represent functionals from $V$ to $R$ where $V$ is the function space in whose dual they lie. This means that neither \mintinline{python}|ufl.Cofunction| nor \mintinline{python}|ufl.Coargument| is a subclass of \mintinline{python}|ufl.Expression|. This is the reason that it's necessary to have separate \mintinline{python}|ufl.Cofunction| nor \mintinline{python}|ufl.Coargument| classes rather than simply allowing \mintinline{python}|ufl.Coefficient| and \mintinline{python}|ufl.Argument| to be defined on a \mintinline{python}|ufl.DualSpace|.

Conversely, a \mintinline{python}|ufl.Cofunction| is an (anti-)linear form. This has a number of consequences. In particular, it means that the if \mintinline{python}|V| is a function space then the following code is perfectly well mathematically defined:
\begin{minted}{python}
    f = ufl.Cofunction(V.dual())
    v = ufl.Argument(V, 0)
    g = ufl.conj(v) * dx + f
\end{minted}
However for this to work, it is necessary to extend the UFL concept of a multilinear form to encompass cofunctions, and to represent the operations on them.

\subsection{2-forms}

What do we get from:
\begin{minted}{python}
    A = assemble(f_2)
\end{minted}
Mathematically this is defined as follows:
\begin{equation}
    A_{ij} = \int \phi_i \psi_j\ \mathrm{d}x
\end{equation}
That is to say, $A$ is a matrix. Recall that $\{\phi_i\}$ is the basis for $V$, which is the function space of argument 0 in this case, and $\{\psi_j\}$ is the basis for $W$, which is argument 1. This means that the assembled operator has its arguments in ascending order, while the form notation has them in descending order. This is a frequent cause of confusion about which we will have to remain aware. FEniCS and Firedrake both agree that assembling a 2-form produces a matrix, though UFL does not have a corresponding class, so currently matrices are outside its scope. However, a matrix is an assembled 2-form in just the same way that a cofunction is an assembled 1-form, so the logical conclusion would be the creation of a \mintinline{python}|ufl.Matrix| class which would behave as an assembled 2-form, and would have algebraic properties analogous to a cofunction. A matrix would presumably have two intrinsic arguments.


\section{The interpolation operator}

Usually we are concerned with vector spaces which are finite-dimensional subspaces of larger, typically infinite dimensional, spaces. In the finite element method, we often define the basis of these finite spaces by defining the space and choosing the dual basis. The primal basis can then be derived by solving a linear system (see, for example, \href{https://finite-element.github.io/2_finite_elements.html}{the finite element course}). Let's briefly examine the dual basis functions, also known as nodes. These are functionals that take in a function and (linearly) produce a scalar. What do such objects look like? The simplest case is probably the point evaluation functional, or Dirac delta distribution. For a function $v: \Omega\rightarrow\mathbb{R}$, the point evaluation functional at the point $x$ is given by:
\begin{equation}
    \delta_x(v) = v(x)
\end{equation}
Other common functionals include the integral of a function over one mesh cell, or the component of a vector value in a particular direction at a particular point. All of these have in common that they are trivially extensible to a much larger space of functions than the finite element function space whose dual they define. For example, point evaluation functionals can be evaluated for any space of functions whose members are well-defined at the points in question. This is useful because it is a very common requirement to approximate some function from a more general space in a finite element function. This most commonly occurs when a forcing function or reference solution is known either from external (physical) data, or from an analytic expression. Suppose $v\in V$ and that $\{\phi_i\}$ is a basis for $V$, with $\{\phi_i^*\}$ the corresponding dual basis. The for a function $f:\Omega\rightarrow\mathbb{R}$ such that the dual functionals are defined, the interpolation of $f$ into $v$ is given by:
\begin{equation}
    \hat{f} = \hat{f}_i \phi_i 
\end{equation}
where:
\begin{equation}
    \hat{f}_i = \phi_i^*(f)
\end{equation}
In other words, the $i$-th basis coefficient is the evaluation of the $i$-th dual basis functional on the function to be interpolated. We can call this operator $I_V(f)$.
\begin{note}
    If $f\in V$ then it is straightforward to show that $I_V(f)=f$. That is to say, interpolation is a projection.
\end{note}
In fact, the interpolation operator is nothing other than the evaluation of the dual basis. We could instead define an operator, a generalisation of the delta distribution, which takes a functional $v\in V^*$ and applies it to a function $u\in U$ where $U$ is a function space on which the functionals in $V^*$ are defined. That is to say:
\begin{equation}
    \delta(u, v) = v(u)
\end{equation}
Notice that $\delta: U\times V^*\rightarrow \mathbb{R}$. Since $V^*$ is itself a vector space, this makes $\delta$ a 2-form, albeit a slightly unusual one. We would be more used to forms in $U\times V\rightarrow\mathbb{R}$.



\section{The delta operator and dual space arguments}

Let's now return to the interpolation operator. If we wish to incorporate it into UFL as a first class citizen then we need to take our extensions of the language just a little further. Let's suppose we can define arguments in dual spaces. These are mathematical objects of a different kind to the arguments we have already met: they are unknown members of $V^*$ rather than $V$. We suppose, therefore, that they are of a new type: \mintinline{python}|ufl.Coargument|. In order to minimise syntactic clutter, one might imagine overloading the object constructor such that \mintinline{python}|ufl.Argument(V.dual, 0)| is valid and returns a \mintinline{python}|ufl.Coargument|.

This enables us to define a new form \mintinline{python}|ufl.Delta| such that if \mintinline{python}|e| is a UFL expression and \mintinline{python}|v_ = ufl.Argument(V.dual, 0)| then \mintinline{python}|delta(e, v_)| is a symbolic expression for the interpolation of \mintinline{python}|e| into $V$. If we assume that \mintinline{python}|e| does not contain any arguments and execute:
\begin{minted}{python}
    f = assemble(Delta(e, v_))
\end{minted}
Then \mintinline{python}|f| will be a \mintinline{python}|Function| in $V$ representing the result of this interpolation. Conversely, if \mintinline{python}|u = Argument (W, 1)| then:
\begin{minted}{python}
    A = assemble(Delta(u, v_))
\end{minted}
results in a matrix which is the interpolation operator from $W$ into $V$. One can also construct the adjoint of this operator by reversing the argument positions:
\begin{minted}{python}
    v = ufl.Argument(W, 0)
    u_ = ufl.Argument(V.dual, 1)
    AT = assemble(ufl.Delta(v, u_))
\end{minted}
As a particular case of interest, if we write:
\begin{minted}{python}
    u = ufl.Argument(V, 1)
    v_ = ufl.Argument(V.dual, 0)
    I = assemble(ufl.Delta(u, v_))
\end{minted}
Then \mintinline{python}|I| is the identity matrix for $V$

For completeness, we can also address the other cases. If we write:
\begin{minted}{python}
    f = firedrake.Cofunction(V.dual)
    c = firedrake.Function(W)
    t = ufl.Delta(c, f)
    s = assemble(t)
\end{minted}
then $t$ is a symbolic expression for $f(c)$ and $s$ is the scalar which results from evaluating it. Indeed, one might want to implement the \mintinline{python}|__call__| special method on \mintinline{python}|ufl.Cofunction| and \mintinline{python}|ufl.Coargument| so that the syntax \mintinline{python}|f(c)| works directly. Note that this would simply return \mintinline{python}|ufl.Delta(c, f)|. \mintinline{python}|ufl.Delta| is still needed as the object which encodes the symbolic operation of dual evaluation.

Finally, if we write:
\begin{minted}{python}
    f = firedrake.Cofunction(V.dual)
    u = ufl.Argument(W, 0)
    g = assemble(ufl.Delta(u, f))
\end{minted} 
Then $g\in W^*$ is the interpolation of $f$ into $W^*$. (Note that Cofunction interpolation is the transpose of function interpolation).

\section{Adjoint}

The  dual or adjoint of a 2-form is the conjugate of that form with its arguments relabelled in reversed order. This carries over to forms which map from or to dual spaces. If we take the example of the delta form again, then:
\begin{equation}
    \delta: V \times W^* \rightarrow \mathbb{R}.
\end{equation}
Equivalently:
\begin{equation}
    \delta: V \rightarrow W.
\end{equation}
If we write $\delta^*$ for the adjoint to $\delta$ then:
\begin{equation}
    \delta^*: W^* \times V \rightarrow \mathbb{R},
\end{equation}
which is to say:
\begin{equation}
    \delta^*: W^* \rightarrow V^*.
\end{equation}
Which is simply another way of saying that cofunction interpolation is the dual of coefficient interpolation.

\section{External operators}

The delta form is simply one example of an form whose first argument is in a dual space. In fact any operator which outputs a \mintinline{python}|Function| and which is linear in any other arguments it has is a form of similar type. Note that such an operator could have known inputs (e.g. coefficients) with respect to which it is nonlinear, it is only the unknown arguments with respect to which it has to be linear. In this context it is important to distinguish between the inputs to such an operator, which we will call its \emph{operands} and arguments. Arguments may appear in operands, but an operand also contain other UFL expressions. For example an operator $N$ might take some UFL expression as an input, evaluate a neural net and return the output as a \mintinline{python}|Function|. That is $N(e, m)\in V$ for a UFL expression $e$, $m\in\mathbb R^k$ and $V$ some function space. Of course saying that $N(e,m)\rightarrow V$ is the same as saying $N(e, m) \times V^* \rightarrow \mathbb{R}$, so an external operator is also a form.

\section{Form composition}

Recall that a $k$-form of type $V_{k-1}\times\ldots \times V_0 \rightarrow \mathbb{R}$ can be interpreted as an operator $V_{k-1}\times\ldots \times V_1 \rightarrow V_0^*$. In other words, it can mathematically be used anywhere were an object in $V_0^*$ is expected. Similarly, the reflexivity of the vector spaces we work with means that a $k$-form of type $V_{k-1}\times\ldots \times V_0^* \rightarrow \mathbb{R}$ can be interpreted as an operator $V_{k-1}\times\ldots \times V_1 \rightarrow V_0$. That is, it can be used where a value in $V_0$ is expected.

Hitherto, UFL forms have only taken inputs from primal spaces and produced outputs in dual spaces, so composing forms by using the output of one as an input to another was not an available option. However, now that there are forms which produce primal space outputs, and forms which accept dual space inputs, we need to examine the consequences of this.

Consider this simple case:
\begin{minted}{python}
    v_ = ufl.Argument(V.dual, 0)
    f = firedrake.Function(W)
    v = ufl.Argument(V, 0)
    F_1 = ufl.Delta(f, v_) * v * dx
    l = assemble(F_1)
\end{minted}
This is a slightly contrived case, though it could really occur if, for example, $W$ is defined on a different mesh from $V$. The assembly algorithm for \mintinline{python}|l| would be:
\begin{minted}{python}
    tmp = firedrake.Function(V)
    l = assemble(ufl.replace(F_1, {ufl.Delta(f, w_): tmp}))
\end{minted}
I.e., we first evaluate the delta, and then substitute the result into the surrounding form. The type of the temporary variable can be inferred from the arguments to the delta. Consider now the 2-form case:
\begin{minted}{python}
    v_ = ufl.Argument(V.dual, 0)
    w = ufl.Argument(W, 1)
    v = ufl.Argument(V, 0)
    F_2 = ufl.Delta(w, v_) * v * dx
    A = assemble(F_2)
\end{minted}
This results in the following assembly algorithm:
\begin{minted}{python3}
    tmp_1 = assemble(Delta(w, v_)) # tmp_1 is a |V| x |W| matrix.
    tmp_2 = assemble(ufl.replace(F_2, {ufl.Delta(w, v_): ufl.Argument(V, 1)}))
    A = tmp_2 @ tmp_1
\end{minted}
Again the, the types of the temporary variables can be inferred from the arguments of the delta. The delta has 2 arguments and they are in the canonical order, so it is replaced by an argument numbered 1 but in the function space dual to the argument 0 function space. The sequence of the matrix multiplication is similarly inferable from the arguments and the sequence of composition (the delta occurs inside the other form, and not vice versa). The general rule is that the form is replaced by an argument in the dual space to its zero argument, and with an argument number which is the next available argument number in the form into which it is being substituted.

\subsection{Arguments of composite forms}

What are the arguments of \mintinline{python}|F_2|? One might be tempted to say \mintinline{python}|v_|, \mintinline{python}|w|, and \mintinline{python}|v|, but this would characterise \mintinline{python}|F_2| as a 3-form rather than a 2-form. It would also have two different arguments numbered 0 (\mintinline{python}|v_|, and \mintinline{python}|v|), so it would not even be a well-formed form. The answer to this puzzle is that the 0 argument of a form nested into another form is consumed by the substitution. In this case, this means that the arguments of the composite form are \mintinline{python}|v| and \mintinline{python}|w|.

\subsection{No substitution for argument 0}
Consider instead the case where the interpolation happens for the test function. By symmetry with \mintinline{python}|F_2|, one might expect to be able to write:
\begin{minted}{python}
    w_ = ufl.Argument(W.dual, 0)
    v = ufl.Argument(V, 0)
    u = ufl.Argument(V, 1)
    F_3 = u * ufl.Delta(v, w_) * dx
\end{minted}
However this is ill-formed since the delta contains two arguments numbered 0. This difficulty is the result of the fact that form composition only makes sense if we think of forms as operators into the dual space of argument 0. In this context, argument 0 is not a form input at all, but is instead a placeholder for the result of evaluating the form for known values of all of its higher-numbered arguments. However, composition of linear operators works in both directions so we can instead write:
\begin{minted}{python}
    w = ufl.Argument(W, 0)
    v = ufl.Argument(W, 0)
    u = ufl.Argument(V, 1)
    F_4 = ufl.Delta(w, u * v * dx)
\end{minted}
Which is well-formed UFL, and mathematically equivalent to what \mintinline{python}|F_3| attempted to achieve. As one might expect, $F_4: V \rightarrow W^*$.

\section{Action}

The action of a form on a coefficient or argument simply replaces the highest numbered argument with that coefficient. This carries over directly to the dual case. If the highest numbered argument of a form lies in a dual space, then the action is only well defined on a cofunction or coargument from the appropriate space.

Form composition means that it should also be possible to take the action of a form on another form, so long as the space of the highest numbered argument of the first form is dual to the space of the 0 argument to the second form. That is, an alternative definition of \mintinline{python}|F_4| is given by:
\begin{minted}{python}
    w = ufl.Argument(W, 0)
    omega = ufl.Argument(W.dual, 1)
    v = ufl.Argument(V, 0)
    u = ufl.Argument(V, 1)
    F_4 = ufl.action(ufl.Delta(w, omega), u * v * dx)
\end{minted}
Of course this lines up with the assembly strategy for \mintinline{python}|F_4|, which would be:
\begin{minted}{python3}
    tmp_1 = assemble(Delta(w_, ufl.Argument(V.dual, 1))
    tmp_2 = assemble(u * v * dx)
    A = tmp_1 @ tmp_2
\end{minted}
\printbibliography

\end{document}
